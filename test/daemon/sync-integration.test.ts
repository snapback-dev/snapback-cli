/**
 * Tests for daemon SyncWorker integration
 *
 * Validates that SyncWorker is properly wired into daemon lifecycle:
 * - Starts when session.begin is called
 * - Stops when daemon shuts down
 * - Non-fatal on failure
 *
 * @vitest-environment node
 */

import { existsSync, mkdirSync, rmSync } from "node:fs";
import { join } from "node:path";
import { afterEach, beforeEach, describe, expect, it, vi } from "vitest";

const TEST_DIR = join(process.cwd(), ".test-daemon-sync");

describe("daemon SyncWorker integration", () => {
	beforeEach(() => {
		if (!existsSync(TEST_DIR)) {
			mkdirSync(TEST_DIR, { recursive: true });
		}
		// Create .snapback directory
		mkdirSync(join(TEST_DIR, ".snapback"), { recursive: true });
	});

	afterEach(() => {
		if (existsSync(TEST_DIR)) {
			rmSync(TEST_DIR, { recursive: true, force: true });
		}
	});

	describe("SyncWorker singleton pattern", () => {
		it("should import SyncWorker from intelligence package", async () => {
			const { SyncWorker, StateStore } = await import("@snapback/intelligence");

			expect(SyncWorker).toBeDefined();
			expect(StateStore).toBeDefined();
		});

		it("should create SyncWorker with valid config", async () => {
			const { SyncWorker, StateStore } = await import("@snapback/intelligence");

			const store = new StateStore({ snapbackDir: join(TEST_DIR, ".snapback") });
			await store.load();

			const worker = new SyncWorker(store, {
				userId: "test-user",
				workspaceId: TEST_DIR,
				syncInterval: 30000,
			});

			expect(worker).toBeDefined();
			await worker.init();

			// Should not throw when started
			worker.start();

			// Should not throw when stopped
			worker.stop();
		});

		it("should handle multiple start/stop cycles", async () => {
			const { SyncWorker, StateStore } = await import("@snapback/intelligence");

			const store = new StateStore({ snapbackDir: join(TEST_DIR, ".snapback") });
			await store.load();

			const worker = new SyncWorker(store, {
				userId: "test-user",
				workspaceId: TEST_DIR,
			});

			await worker.init();

			// Multiple cycles should not throw
			worker.start();
			worker.stop();
			worker.start();
			worker.stop();

			expect(true).toBe(true);
		});
	});

	describe("daemon lifecycle integration", () => {
		it("should verify getSyncWorker returns consistent instances", async () => {
			// This tests the singleton pattern conceptually
			// In production, daemon maintains Map<string, SyncWorker>
			const { SyncWorker, StateStore } = await import("@snapback/intelligence");

			const instances = new Map<string, InstanceType<typeof SyncWorker>>();

			const getOrCreate = async (workspace: string, userId: string) => {
				const key = `${workspace}:${userId}`;
				if (!instances.has(key)) {
					const store = new StateStore({ snapbackDir: join(workspace, ".snapback") });
					await store.load();
					const worker = new SyncWorker(store, { userId, workspaceId: workspace });
					await worker.init();
					instances.set(key, worker);
				}
				return instances.get(key);
			};

			const worker1 = await getOrCreate(TEST_DIR, "user1");
			const worker2 = await getOrCreate(TEST_DIR, "user1");

			// Same key should return same instance
			expect(worker1).toBe(worker2);

			// Different user should create new instance
			const worker3 = await getOrCreate(TEST_DIR, "user2");
			expect(worker3).not.toBe(worker1);

			// Cleanup
			for (const worker of instances.values()) {
				worker.stop();
			}
		});

		it("should cleanup all workers on stopAll", async () => {
			const { SyncWorker, StateStore } = await import("@snapback/intelligence");

			const instances = new Map<string, InstanceType<typeof SyncWorker>>();

			// Create multiple workers
			for (let i = 0; i < 3; i++) {
				const workspace = join(TEST_DIR, `ws${i}`);
				mkdirSync(join(workspace, ".snapback"), { recursive: true });

				const store = new StateStore({ snapbackDir: join(workspace, ".snapback") });
				await store.load();

				const worker = new SyncWorker(store, {
					userId: `user${i}`,
					workspaceId: workspace,
				});
				await worker.init();
				worker.start();

				instances.set(`${workspace}:user${i}`, worker);
			}

			expect(instances.size).toBe(3);

			// Stop all (mimics stopAllSyncWorkers)
			for (const [_key, worker] of instances) {
				worker.stop();
			}
			instances.clear();

			expect(instances.size).toBe(0);
		});
	});

	describe("error handling", () => {
		it("should handle missing snapback directory gracefully", async () => {
			const { StateStore } = await import("@snapback/intelligence");

			// Non-existent path
			const store = new StateStore({
				snapbackDir: join(TEST_DIR, "nonexistent", ".snapback"),
			});

			// Should create directory on load
			await store.load();
			expect(existsSync(join(TEST_DIR, "nonexistent", ".snapback"))).toBe(true);
		});

		it("should emit error events without crashing", async () => {
			const { SyncWorker, StateStore } = await import("@snapback/intelligence");

			const store = new StateStore({ snapbackDir: join(TEST_DIR, ".snapback") });
			await store.load();

			const worker = new SyncWorker(store, {
				userId: "test",
				workspaceId: TEST_DIR,
			});

			const errorHandler = vi.fn();
			worker.on("error", errorHandler);

			await worker.init();

			// Emit error manually to test handler
			worker.emit("error", new Error("Test error"));

			expect(errorHandler).toHaveBeenCalled();

			worker.stop();
		});
	});
});
